import { PoseLandmarker, FilesetResolver, DrawingUtils } from "@mediapipe/tasks-vision";
// ========== REFER√äNCIAS DOS ELEMENTOS HTML ==========
const videoElement = document.getElementById('webcam');
const canvasElement = document.getElementById('output_canvas');
const statusElement = document.getElementById('status');
const startBtn = document.getElementById('start_btn');
const stopBtn = document.getElementById('stop_btn');
const fpsElement = document.getElementById('fps');

// Configurar as dimens√µes do canvas para corresponder ao v√≠deo
canvasElement.width = 640;
canvasElement.height = 480;

// Inicializar contexto de desenho
const canvasCtx = canvasElement.getContext('2d');
const drawingUtils = new DrawingUtils(canvasCtx);

// ========== VARI√ÅVEIS GLOBAIS ==========
let poseLandmarker = undefined;
let webcamStream = null;
let isRunning = false;
let animationId = null;

// Vari√°veis de √Åudio
let audioCtx = null;
let audioSource = null;
let lowPassFilter = null;
let gainNode = null;

// Vari√°veis para calcular FPS
let lastFrameTime = performance.now();
let fps = 0;
let frameCount = 0;

// ========== CARREGAR IA ==========
// Essa fun√ß√£o ser√° respons√°vel por carregar a IA
async function createPoseLandmarker() {
  try {
    // O FilesetResolver busca os arquivos necess√°rios na rede (WASM e modelos)
    const vision = await FilesetResolver.forVisionTasks(
      "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm"
    );

    // Aqui inicializamos o marcador de pose com as nossas configura√ß√µes
    poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
      baseOptions: {
        modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_heavy/float16/1/pose_landmarker_heavy.task`,
        delegate: "GPU" // For√ßamos o uso da placa de v√≠deo para ser mais r√°pido
      },
      runningMode: "VIDEO", // Essencial para processar frames em sequ√™ncia
      numPoses: 1 // Queremos apenas uma pessoa (o jogador) na tela
    });
    
    console.log("‚úÖ IA Carregada e pronta para o Aura Check!");
    
    // Atualizar status quando a IA estiver pronta
    if (statusElement.innerText.includes("Carregando IA")) {
      statusElement.innerText = "üéØ Aura detectada! Dance e se mova!";
    }
  } catch (error) {
    console.error("‚ùå Erro ao carregar IA:", error);
    statusElement.innerText = "‚ùå Erro ao carregar IA. Recarregue a p√°gina.";
    alert("Erro ao carregar o modelo de IA. Verifique sua conex√£o e recarregue a p√°gina.");
  }
}

createPoseLandmarker();


// ========== MOTOR DE √ÅUDIO ==========
async function setupAudio() {
  try {
    // 1. Cria o contexto de √°udio do navegador
    audioCtx = new (window.AudioContext || window.webkitAudioContext)();

    
    // 2. Cria o nosso "pedal" de erro (Filtro Low Pass)
    lowPassFilter = audioCtx.createBiquadFilter();
    lowPassFilter.type = "lowpass";
    lowPassFilter.frequency.value = 20000; // 20000Hz = Som 100% limpo

    // 2.5 Cria o "pedal" de Volume (Gain) <-- NOVO
    gainNode = audioCtx.createGain();
    gainNode.gain.value = 1; // Come√ßa no volume m√°ximo (1 = 100%)  

    // 3. Busca a m√∫sica na pasta public
    const response = await fetch('/NO-BATIDAO.mp3');
    const arrayBuffer = await response.arrayBuffer();
    const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);

    // 4. Cria o tocador
    audioSource = audioCtx.createBufferSource();
    audioSource.buffer = audioBuffer;
    audioSource.loop = true; // Deixa a m√∫sica em loop

    // 5. Conecta os cabos: Tocador -> Filtro -> Caixa de Som
    audioSource.connect(lowPassFilter);
    lowPassFilter.connect(gainNode);
    lowPassFilter.connect(audioCtx.destination);

    // 6. D√° o play!
    audioSource.start(0);
    console.log("‚úÖ √Åudio carregado e tocando!");
  } catch (error) {
    console.error("‚ùå Erro ao carregar o √°udio:", error);
    alert("N√£o foi poss√≠vel carregar a musica.mp3. Verifique se o nome est√° correto na pasta public.");
  }
}

// ========== LOOP DE DETEC√á√ÉO ==========
/**
 * Esta fun√ß√£o roda em loop infinito (enquanto o jogo estiver ativo)
 */
async function predictWebcam() {
  if (!isRunning) return;

  // 1. Limpamos o canvas para desenhar o novo frame
  canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);

  // 2. S√≥ processamos se a IA j√° estiver carregada e o v√≠deo pronto
  if (poseLandmarker !== undefined && videoElement.readyState >= 2) {
    let startTimeMs = performance.now();

    // 3. A IA l√™ o frame atual do elemento <video>
    const results = poseLandmarker.detectForVideo(videoElement, startTimeMs);

    // 4. Se a IA encontrou um corpo, vamos desenh√°-lo!
    if (results.landmarks && results.landmarks.length > 0) {
      for (const landmark of results.landmarks) {
        // Desenha as conex√µes (linhas entre os pontos)
        drawingUtils.drawConnectors(landmark, PoseLandmarker.POSE_CONNECTIONS, {
          color: "#00FFCC", // Cor Neon para a nossa Aura
          lineWidth: 4
        });
        
        // Desenha os pontos individuais (articula√ß√µes)
        drawingUtils.drawLandmarks(landmark, {
          color: "#FF00BB", // Rosa choque para destacar as articula√ß√µes
          lineWidth: 2
        });
      }

      // Pegamos a primeira pessoa detectada
const landmarks = results.landmarks[0]; 

// Refer√™ncias (Y diminui conforme sobe na tela)
const noseY = landmarks[0].y;
const leftWristY = landmarks[15].y;
const rightWristY = landmarks[16].y;

// L√≥gica do Movimento: "M√£os ao alto!"
const isHandsUp = leftWristY < noseY && rightWristY < noseY;

if (isHandsUp) {
    statusElement.innerText = "‚ú® AURA MAXIMA! M√£os ao alto!";
    statusElement.style.color = "#00FFCC";
    
    // Som Limpo: Volta o filtro para 20.000Hz suavemente em 0.1s
    if (audioCtx && lowPassFilter && gainNode) {
        lowPassFilter.frequency.setTargetAtTime(20000, audioCtx.currentTime, 0.1);
        gainNode.gain.setTargetAtTime(1.0, audioCtx.currentTime, 0.1);
    }
} else {
    statusElement.innerText = "‚ö†Ô∏è M√£os para baixo! Aura enfraquecendo...";
    statusElement.style.color = "#FF00BB";
    
    // Som Abafado: Derruba o filtro para 400Hz suavemente em 0.1s
    if (audioCtx && lowPassFilter && gainNode) {
        lowPassFilter.frequency.setTargetAtTime(400, audioCtx.currentTime, 0.1);
        gainNode.gain.setTargetAtTime(0.01, audioCtx.currentTime, 0.1);
    }
}

    }

    // Calcular FPS
    frameCount++;
    const currentTime = performance.now();
    const delta = currentTime - lastFrameTime;
    
    if (delta >= 1000) { // Atualiza FPS a cada 1 segundo
      fps = Math.round((frameCount * 1000) / delta);
      frameCount = 0;
      lastFrameTime = currentTime;
      if (fpsElement) {
        fpsElement.innerText = `FPS: ${fps}`;
      }
    }
  }

  // 5. Chama a si mesma para criar o loop cont√≠nuo
  animationId = window.requestAnimationFrame(predictWebcam);
}

// ========== INICIALIZA√á√ÉO DA WEBCAM ==========
/**
 * Fun√ß√£o ass√≠ncrona para inicializar a c√¢mera.
 * Usamos 'async' porque o acesso ao hardware n√£o √© instant√¢neo.
 */
async function initWebcam() {
  statusElement.innerText = "Solicitando acesso √† c√¢mera...";

  try {
    /**
     * O navigator.mediaDevices.getUserMedia √© o m√©todo padr√£o da Web 
     * para acessar dispositivos de entrada (v√≠deo e √°udio).
     */
    const stream = await navigator.mediaDevices.getUserMedia({
      video: {
        width: 640,
        height: 480,
        facingMode: "user" // Garante o uso da c√¢mera frontal em celulares
      },
      audio: false // Para o BBA, n√£o precisamos do microfone agora
    });

    // 2. Conectamos o fluxo da c√¢mera (stream) ao elemento de v√≠deo
    videoElement.srcObject = stream;
    webcamStream = stream;
    isRunning = true;

    // 3. Atualizamos a interface para o usu√°rio
    statusElement.innerText = "‚úÖ C√¢mera ativa! Carregando IA...";
    startBtn.style.display = "none"; // Esconde o bot√£o ap√≥s iniciar
    stopBtn.style.display = "inline-block"; // Mostra bot√£o de parar
    if (fpsElement) {
      fpsElement.style.display = "block";
    }

    // Iniciar o √°udio junto com a c√¢mera
if (!audioCtx) {
  await setupAudio();
} else if (audioCtx.state === 'suspended') {
  audioCtx.resume();
}

    console.log("Stream da webcam iniciado com sucesso.");
  } catch (error) {
    // 4. Tratamento de erros (Ex: Usu√°rio negou a permiss√£o)
    console.error("Erro t√©cnico ao acessar webcam:", error);
    statusElement.innerText = "‚ùå Erro: " + error.message;
    alert("Para o Beat Bound Aura funcionar, precisamos da sua c√¢mera!");
  }
}

// ========== PARAR WEBCAM ==========
// Fun√ß√£o para parar a webcam
function stopWebcam() {
  if (webcamStream) {
    // Para todas as tracks do stream
    webcamStream.getTracks().forEach(track => track.stop());
    videoElement.srcObject = null;
    webcamStream = null;
  }

  // Para a anima√ß√£o
  isRunning = false;
  if (animationId) {
    cancelAnimationFrame(animationId);
    animationId = null;
  }

  // Limpa o canvas
  canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);

  // Atualiza a interface
  statusElement.innerText = "C√¢mera desligada. Pronto para iniciar novamente!";
  startBtn.style.display = "inline-block";
  stopBtn.style.display = "none";
  if (fpsElement) {
    fpsElement.style.display = "none";
    fpsElement.innerText = "FPS: 0";
  }
  
  // Reseta contadores
  fps = 0;
  frameCount = 0;
  lastFrameTime = performance.now();

  // Parar o √°udio
if (audioSource) {
  audioSource.stop();
  audioSource.disconnect();
  audioSource = null;
}
if (audioCtx) {
  audioCtx.close();
  audioCtx = null;
}
}

// ========== EVENT LISTENERS ==========
videoElement.addEventListener("loadeddata", predictWebcam);
startBtn.addEventListener('click', initWebcam);
stopBtn.addEventListener('click', stopWebcam);

// ========== RESPONSIVIDADE ==========
// Responsividade - Ajustar canvas ao redimensionar janela
function resizeCanvas() {
  const container = document.querySelector('.canvas-container');
  if (!container) return;

  const containerWidth = container.offsetWidth;
  const aspectRatio = 640 / 480;
  const newHeight = containerWidth / aspectRatio;

  container.style.height = `${newHeight}px`;
}

// Ajustar ao carregar e ao redimensionar
window.addEventListener('load', resizeCanvas);
window.addEventListener('resize', resizeCanvas);
